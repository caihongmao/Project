{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaze_estimator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb15fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_estimate = GazeEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fba8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "success, img = cap.read()\n",
    "img  = cv2.resize(img,(960, 720))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2224077",
   "metadata": {},
   "outputs": [],
   "source": [
    "img  = cv2.resize(img,(640, 480))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = gaze_estimate.detect_faces(img)\n",
    "for face in faces:\n",
    "    gaze_estimate.estimate_gaze(img, face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch, yaw = np.rad2deg(face.vector_to_angle(face.gaze_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b20380",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(face.normalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544667dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(face.normalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0abdd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\gaze_space_obj_select\\methods\\beamdetect.py:108: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'a' in obj_:\n",
      "R:\\gaze_space_obj_select\\methods\\beamdetect.py:113: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'b' in obj_:\n",
      "R:\\gaze_space_obj_select\\methods\\beamdetect.py:118: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'd' in obj_:\n",
      "R:\\gaze_space_obj_select\\methods\\beamdetect.py:123: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'c' in obj_:\n"
     ]
    }
   ],
   "source": [
    "from gaze_estimator import *\n",
    "from methods.realsense import *\n",
    "from methods.filter import *\n",
    "from methods.gaze import *\n",
    "from methods.beamdetect import *\n",
    "from common import Visualizer\n",
    "from utils import get_3d_face_model\n",
    "\n",
    "gaze_estimator = GazeEstimator()\n",
    "face_model_3d = get_3d_face_model()\n",
    "visualizer = Visualizer(gaze_estimator.camera,\n",
    "                        face_model_3d.NOSE_INDEX)\n",
    "\n",
    "# 初始化RealSense相机\n",
    "pipeline, alignedFs = realsenseConfig()\n",
    "frames = pipeline.wait_for_frames()\n",
    "frames = alignedFs.process(frames)\n",
    "image, depth = color_depth(frames)\n",
    "\n",
    "# 获取相机内参\n",
    "intrinsics = pipeline.get_active_profile().get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "# 初始化滤波器\n",
    "smooth_filter = KalmanFilter(4, 2, 0.001, 0.1)\n",
    "# smooth_filter = OneEuroFilter(1.0, 0.01)\n",
    "\n",
    "\n",
    "def process_image(image) -> None:\n",
    "    faces = gaze_estimator.detect_faces(image)\n",
    "    for face in faces:\n",
    "        gaze_estimator.estimate_gaze(image, face)\n",
    "        pitch, yaw = face.vector_to_angle(face.gaze_vector)\n",
    "        center = np.average(face.bbox,axis=0)\n",
    "        # 卡尔曼滤波和可视化\n",
    "        smooth_filter.process([pitch, yaw])\n",
    "        gaze = smooth_filter.state.reshape(-1)[:2]\n",
    "        draw_gaze(canvas, face.landmarks[168], gaze, length=200.0, thickness=2, color=(255, 0, 0))\n",
    "        return gaze, face\n",
    "    return False\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with torch.no_grad():\n",
    "    while True:\n",
    "        # _, img = cap.read()\n",
    "\n",
    "        # 获取深度图和彩色图\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        frames = alignedFs.process(frames)\n",
    "        # 获取关键帧\n",
    "        img, depth= color_depth(frames)\n",
    "\n",
    "        img = np.flip(img, axis=1)\n",
    "        canvas = img.copy()\n",
    "    \n",
    "        # 推理获得gaze\n",
    "        res = process_image(img)\n",
    "        if  res is not False:\n",
    "            gaze, face = res\n",
    "            gaze_vector = pitchyaw_to_vector(np.array([gaze]))[0]\n",
    "            vec_pos = face.landmarks[168].astype('int')\n",
    "            vec_pos[0] = 1280 - vec_pos[0]\n",
    "            coord_ = rs.rs2_deproject_pixel_to_point(intrinsics, vec_pos, depth.get_distance(vec_pos[0], vec_pos[1]))\n",
    "\n",
    "            sphere_list = {\n",
    "                'a':[-0.40, -0.1, -0.2, 0.3],\n",
    "                'b':[0.40, -0.1, -0.2, 0.3],\n",
    "                }\n",
    "     \n",
    "            rectangle_list = {\n",
    "                'c':[(-0.7, -0.5, 0.2), (-0.7, -0.9, 0.2), (-0.7, -0.5, -0.5), (-0.7, -0.9, -0.5)],\n",
    "                'd':[(0.7, -0.5, 0.2), (0.7, -0.9, 0.2), (0.7, -0.5, -0.5), (0.7, -0.9, -0.5)],\n",
    "                }\n",
    "            \n",
    "            image = beam_obj(np.array(coord_), gaze_vector, sphere_list, rectangle_list)\n",
    "            cv2.imshow('Image with Rectangles', image)\n",
    "\n",
    "\n",
    "        cv2.imshow('image', canvas)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9810388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [-0.4, -0.1, -0.2, 0.3], 'b': [0.4, -0.1, -0.2, 0.3]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sphere_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = gaze_estimator.detect_faces(img)\n",
    "for face in faces:\n",
    "    gaze_estimator.estimate_gaze(img, face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5586cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "face.bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e91025",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(face.bbox,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "face.landmarks[168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9e199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcuda",
   "language": "python",
   "name": "torchcuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
