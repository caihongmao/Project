{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27817f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import scipy.io as sio\n",
    "import utils.gaze as gaze_util\n",
    "from utils.gazemap import *\n",
    "\n",
    "class ColumbiaGaze(Dataset):\n",
    "\n",
    "    def __init__(self, dir: str = './ColumbiaGazeDataSet/datasets_columbia/L'):\n",
    "        self.dir = dir\n",
    "        self.eval_entries = []  # 用于存储数据集信息\n",
    "\n",
    "        # 从文件中加载数据集信息\n",
    "        self._load_data_entries()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eval_entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self._load_sample(idx)\n",
    "\n",
    "    def _load_data_entries(self):\n",
    "        # 从数据集目录中获取数据集信息\n",
    "        # 你需要根据实际的数据集结构和文件名加载数据集信息\n",
    "        # 下面是一个示例，你需要根据你的数据集做出相应的修改\n",
    "        data_files = glob.glob(os.path.join(self.dir, '*.mat'))\n",
    "        for data_file in data_files:\n",
    "            data = sio.loadmat(data_file)\n",
    "            entry = {\n",
    "                'img': data['image'],  # 从MAT文件中加载图像数据\n",
    "                'gaze': data['gaze'],  # 从MAT文件中加载注视点数据\n",
    "                'side': data['side']    # 从MAT文件中加载侧面信息\n",
    "            }\n",
    "            self.eval_entries.append(entry)\n",
    "\n",
    "    def _load_sample(self, i):\n",
    "        entry = self.eval_entries[i]\n",
    "\n",
    "        img = entry['img']\n",
    "        side = entry['side']\n",
    "        gaze = entry['gaze']\n",
    "\n",
    "        # 对图像进行预处理\n",
    "        img = cv2.equalizeHist(img)\n",
    "        img_ = img / 255.\n",
    "        img_ = img_ * 2 - 1\n",
    "        img_ = img_.astype(np.float32)\n",
    "\n",
    "        return {\n",
    "            'eye': torch.tensor(img_.astype(np.float32)).unsqueeze(0),\n",
    "            'side': side,\n",
    "            'gaze': torch.tensor(gaze.astype(np.float32)),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "glob.glob(os.path.join( './ColumbiaGazeDataSet/datasets_columbia/L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f53d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import utils.gaze as gaze_util\n",
    "from utils.gazemap import *\n",
    "\n",
    "class ColumbiaGaze(Dataset):\n",
    "\n",
    "    def __init__(self, dir: str = './ColumbiaGazeDataSet/datasets_columbia/L'):\n",
    "        self.dir = dir\n",
    "        self.eval_entries = []\n",
    "\n",
    "        # 加载数据集信息\n",
    "        self._load_data_entries()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eval_entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self._load_sample(idx)\n",
    "\n",
    "    def _load_data_entries(self):\n",
    "        # 根据图像文件名解析数据集信息\n",
    "        image_files = glob.glob(os.path.join(self.dir, '**', '*.jpg'), recursive=True)\n",
    "        for image_file in image_files:\n",
    "            entry = {\n",
    "                'img_path': image_file, \n",
    "            }\n",
    "            self.eval_entries.append(entry)\n",
    "\n",
    "    def _load_sample(self, i):\n",
    "        entry = self.eval_entries[i]\n",
    "\n",
    "        img_path = entry['img_path']        \n",
    "        array = img_path[:-4].split('_')\n",
    "        gaze = []\n",
    "        gaze.append(int(array[-2][:-1]))\n",
    "        gaze.append(int(array[-1][:-1]))\n",
    "        gaze =np.array(gaze) / 180 / np.pi\n",
    "\n",
    "        # 从图像文件加载图像数据\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # 对图像进行预处理\n",
    "        img = cv2.equalizeHist(img)\n",
    "        img_ = img / 255.\n",
    "        img_ = img_ * 2 - 1\n",
    "        img_ = img_.astype(np.float32)\n",
    "        \n",
    "        gmap = from_gaze2d(gaze.astype(np.float32))\n",
    "\n",
    "        return {\n",
    "            'eye': torch.tensor(img_.astype(np.float32)).unsqueeze(0),\n",
    "            'gaze': torch.tensor(gaze.astype(np.float32)).unsqueeze(0),\n",
    "            'gmap': torch.tensor(gmap.astype(np.float32)).unsqueeze(0)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c936f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(datasets[0]['eye'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bb55bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dpg_hm_18_double import *\n",
    "from models.dpg import *\n",
    "from utils.gazemap import *\n",
    "from utils.gaze import *\n",
    "from trainers.dpg_hm_trainer_18 import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from datasources.unityeyes import *\n",
    "from datasources.columbia_gaze_double import *\n",
    "\n",
    "# GPU\n",
    "import torch.backends.cudnn as cudnn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# 原始模型\n",
    "net = DPGHM18()\n",
    "net.load_state_dict(torch.load('models/dpghm18/model-dpghm18-0.4-epoch-21-loss-0.6584.pth'))\n",
    "\n",
    "for param in net.Hourglass_net.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in net.DenseNet.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in net.HM.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# self.Hourglass_module = Hourglass_module(64, 64, 2)\n",
    "# self.conv2 = conv1x1(64, 1)\n",
    "# self.bn2 = nn.BatchNorm2d(1)\n",
    "# self.relu2= nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "# 数据\n",
    "train_dataset = UnityEyesDataset('datasets/train', eye_image_shape=(36, 60), random_difficulty=True) \n",
    "val_dataset = UnityEyesDataset('datasets/val', eye_image_shape=(36, 60), random_difficulty=True)\n",
    "\n",
    "dataset = ColumbiaGaze()\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)  # 80% 用于训练\n",
    "val_size = dataset_size - train_size  # 剩余部分用于验证\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                                pin_memory=True, \n",
    "                                drop_last=True,\n",
    "#                                 shuffle=True,\n",
    "                                batch_size=batch_size)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                                pin_memory=True, \n",
    "                                drop_last=False,\n",
    "                                batch_size=batch_size)\n",
    "\n",
    "# 训练\n",
    "trainer = dpg_hm_trainer_18(net, train_dataloader, val_dataloader, \n",
    "                     device=device, \n",
    "                     batch_size=batch_size, \n",
    "                     version = '0.5',\n",
    "                     initial_learning_rate = 1e-4,\n",
    "                     epochs=200, \n",
    "                     start_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f13a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0ad0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample['eye'].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bff90d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concat() received an invalid combination of arguments - got (Tensor, Tensor, axis=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16524\\4267895688.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgaze_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDPGHM18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgaze_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDPGHM18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_right\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgaze_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgaze_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgaze_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: concat() received an invalid combination of arguments - got (Tensor, Tensor, axis=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "img_left = x[:,:,:, :60]\n",
    "img_right = x[:,:,:, 60:]\n",
    "gaze_left = net.DPGHM18(img_left)[0]\n",
    "gaze_right = net.DPGHM18(img_right)[0]\n",
    "gaze_concat = torch.concat([gaze_left, gaze_right], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb0cf859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1230,  0.2017],\n",
       "        [ 0.2355,  0.0759],\n",
       "        [ 0.3004,  0.2032],\n",
       "        [-0.0293,  0.1211],\n",
       "        [ 0.1428,  0.3254],\n",
       "        [ 0.2253,  0.0907],\n",
       "        [ 0.1008,  0.1462],\n",
       "        [ 0.2567,  0.2417]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaze_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95561ac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concat() received an invalid combination of arguments - got (tuple, tuple), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16524\\461627798.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDPGHM18Double\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\envs\\torchcuda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mQ:\\gaze_estimation\\models\\dpg_hm_18_double.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    407\u001b[0m        \u001b[0mgaze_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDPGHM18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m        \u001b[0mgaze_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDPGHM18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_right\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m        \u001b[0mgaze_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgaze_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgaze_right\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m        \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinearGazeBefore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgaze_concat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m        \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinearGazeAfter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: concat() received an invalid combination of arguments - got (tuple, tuple), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "net = DPGHM18Double()\n",
    "net.cuda()\n",
    "net(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6120c467",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net.(img_left.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e646523",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_left.cuda().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00fbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "net(sample['eye'].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cff0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['gaze'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf132f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['gmap'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ColumbiaGaze()\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)  # 80% 用于训练\n",
    "val_size = dataset_size - train_size  # 剩余部分用于验证\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                                pin_memory=True, \n",
    "                                drop_last=True,\n",
    "                                shuffle=True,\n",
    "                                batch_size=batch_size)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                                pin_memory=True, \n",
    "                                drop_last=False,\n",
    "                                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa659f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdc553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dpg_hm_18_double import *\n",
    "from models.dpg import *\n",
    "from utils.gazemap import *\n",
    "from utils.gaze import *\n",
    "from trainers.dpg_hm_trainer_18 import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from datasources.unityeyes import *\n",
    "from datasources.columbia_gaze_double import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95acb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DPGHM18Double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c045c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据\n",
    "batch_size = 18\n",
    "dataset = ColumbiaGaze()\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)  # 80% 用于训练\n",
    "val_size = dataset_size - train_size  # 剩余部分用于验证\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                                pin_memory=True, \n",
    "                                drop_last=True,\n",
    "                                shuffle=True,\n",
    "                                batch_size=batch_size)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                                pin_memory=True, \n",
    "                                drop_last=False,\n",
    "                                batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d285a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[0]['eye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f712e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_left = x[:,:,:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb849db",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.DPGHM18(img_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a424daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "       img_left = x[:,:,:60]\n",
    "       img_right = x[:,:,60:]\n",
    "       gaze_left = self.DPGHM18(img_left)\n",
    "       gaze_right = self.DPGHM18(img_right)\n",
    "       gaze_concat = torch.concat(gaze_left, gaze_right)\n",
    "       x = self.linearGazeBefore(gaze_concat)\n",
    "       x = self.linearGazeAfter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626dbcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net(dataset[0]['eye'].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13517164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import utils.gaze as gaze_util\n",
    "from utils.gazemap import *\n",
    "\n",
    "class ColumbiaGaze(Dataset):\n",
    "\n",
    "    def __init__(self, dir: str = './ColumbiaGazeDataSet/datasets_columbia/L'):\n",
    "        self.dir = dir\n",
    "        self.eval_entries = []\n",
    "\n",
    "        # 加载数据集信息\n",
    "        self._load_data_entries()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eval_entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self._load_sample(idx)\n",
    "\n",
    "    def _load_data_entries(self):\n",
    "        # 根据图像文件名解析数据集信息\n",
    "        image_files = glob.glob(os.path.join(self.dir, '**', '*.jpg'), recursive=True)\n",
    "        for image_file in image_files:\n",
    "            image_file_ = image_file[:40] + 'R' + image_file[41:]\n",
    "            entry = {\n",
    "                'img_path_left': image_file, \n",
    "                'img_path_right': image_file, \n",
    "            }\n",
    "            self.eval_entries.append(entry)\n",
    "\n",
    "    def _load_sample(self, i):\n",
    "        entry = self.eval_entries[i]\n",
    "        img_path_left = entry['img_path_left']    \n",
    "        img_path_right = entry['img_path_right']  \n",
    "        \n",
    "#         left\n",
    "        array = img_path_left[:-4].split('_')\n",
    "        gaze = []\n",
    "        gaze.append(int(array[-2][:-1]))\n",
    "        gaze.append(int(array[-1][:-1]))\n",
    "        gaze =np.array(gaze) / 180 * np.pi\n",
    "        \n",
    "        \n",
    "        img_left = cv2.imread(img_path_left)\n",
    "        img_right = cv2.imread(img_path_right)\n",
    "        img = np.concatenate([img_left, img_right], axis=1)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 对图像进行预处理\n",
    "        img_ = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img_ = cv2.equalizeHist(img_)\n",
    "        img_ = img_ / 255.\n",
    "        img_ = img_ * 2 - 1\n",
    "        img_ = img_.astype(np.float32)\n",
    "        gmap = from_gaze2d(gaze.astype(np.float32))\n",
    "\n",
    "        return {\n",
    "            'eye': torch.tensor(img_.astype(np.float32)).unsqueeze(0),\n",
    "            'gaze_left': torch.tensor(gaze.astype(np.float32)),\n",
    "            'gmap': torch.tensor(gmap.astype(np.float32)),\n",
    "            'img': img\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e92eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ColumbiaGaze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['eye'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s[40] = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e653939e",
   "metadata": {},
   "outputs": [],
   "source": [
    " './ColumbiaGazeDataSet/datasets_columbia/L\\\\0001\\\\0001_2m_-15P_-10V_-10H.jpg'[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679884d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcuda",
   "language": "python",
   "name": "torchcuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
